{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4ca3c6-259e-4f51-8570-1f98e72e1d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train_dataset...\n",
      "train_dataset loaded.\n",
      "Loading val_dataset...\n",
      "val_dataset loaded.\n",
      "Creating DataLoaders...\n",
      "DataLoaders created.\n",
      "Dataset sizes: {'train': 50000, 'val': 10000}\n",
      "Class names: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "Creating model...\n",
      "Model created.\n",
      "\n",
      "Epoch 0/9\n",
      "----------\n",
      "Starting train phase for Epoch 0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71237516404341ce90fda8e75316542e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 0:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n",
      "   Fetched a batch in train phase.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 107\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;66;03m# Add this block to ensure train_model is called directly\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     model_trained = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     torch.save(model_trained.state_dict(), \u001b[33m'\u001b[39m\u001b[33mapp/image_classification_model.pth\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    109\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel saved to app/image_classification_model.pth\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[39m\n\u001b[32m     72\u001b[39m optimizer.zero_grad()\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.set_grad_enabled(phase == \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     _, preds = torch.max(outputs, \u001b[32m1\u001b[39m)\n\u001b[32m     76\u001b[39m     loss = criterion(outputs, labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/timm/models/resnet.py:636\u001b[39m, in \u001b[36mResNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.forward_head(x)\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/timm/models/resnet.py:625\u001b[39m, in \u001b[36mResNet.forward_features\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    623\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.layer1(x)\n\u001b[32m    624\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.layer2(x)\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    626\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.layer4(x)\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/timm/models/resnet.py:115\u001b[39m, in \u001b[36mBasicBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    112\u001b[39m x = \u001b[38;5;28mself\u001b[39m.act1(x)\n\u001b[32m    113\u001b[39m x = \u001b[38;5;28mself\u001b[39m.aa(x)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m x = \u001b[38;5;28mself\u001b[39m.bn2(x)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.se \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml-image-classifier-cifar10/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Step 0: Install Libraries (if running in a fresh environment) ---\n",
    "# Uncomment and run this cell if you're ever in a new environment (like Google Colab)\n",
    "# !pip install torch torchvision timm pillow tqdm\n",
    "\n",
    "# --- Step 1: Import Necessary Libraries ---\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import copy\n",
    "# from tqdm.notebook import tqdm # We're removing this for now due to previous issues\n",
    "\n",
    "# --- Step 2: Set Up Device (Apple MPS GPU, or CPU) ---\n",
    "# This intelligently selects the best available device for your Mac.\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    # For MPS, num_workers > 0 might not provide benefit and can sometimes cause issues.\n",
    "    # It's often recommended to stick to 0 for MPS DataLoaders.\n",
    "    # If you experience hangs later, ensure this remains 0.\n",
    "    num_workers_dataloader = 0\n",
    "elif torch.cuda.is_available(): # For external NVIDIA GPUs (unlikely on M4 Air)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    num_workers_dataloader = 4 # Or adjust based on your external GPU setup\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    # For CPU, num_workers=0 is most robust for avoiding hangs.\n",
    "    # For a 10-core CPU, you could try 2-4 workers if you experience long data loading times\n",
    "    # AFTER the initial batches start moving, but stick to 0 for robustness.\n",
    "    num_workers_dataloader = 0\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"DataLoader num_workers set to: {num_workers_dataloader}\")\n",
    "\n",
    "# --- Step 3: Data Preparation (CIFAR-10) ---\n",
    "# Define CIFAR-10 specific normalization values (mean and std)\n",
    "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar10_std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "# Define transformations for training and validation sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cifar10_mean, cifar10_std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cifar10_mean, cifar10_std)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load CIFAR-10 Dataset\n",
    "data_root_path = './data' # Define path to data directory\n",
    "os.makedirs(data_root_path, exist_ok=True) # Ensure data directory exists\n",
    "\n",
    "print(\"Loading train_dataset...\")\n",
    "train_dataset = datasets.CIFAR10(root=data_root_path, train=True, download=True, transform=data_transforms['train'])\n",
    "print(\"train_dataset loaded.\")\n",
    "\n",
    "print(\"Loading val_dataset...\")\n",
    "val_dataset = datasets.CIFAR10(root=data_root_path, train=False, download=True, transform=data_transforms['val'])\n",
    "print(\"val_dataset loaded.\")\n",
    "\n",
    "# Create a dictionary of datasets\n",
    "image_datasets = {'train': train_dataset, 'val': val_dataset}\n",
    "\n",
    "# Create DataLoaders\n",
    "print(\"Creating DataLoaders...\")\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32,\n",
    "                             shuffle=True if x == 'train' else False,\n",
    "                             num_workers=num_workers_dataloader,\n",
    "                             pin_memory=True if device.type == 'mps' else False # Pin memory for MPS/CUDA if available\n",
    "                            )\n",
    "               for x in ['train', 'val']}\n",
    "print(\"DataLoaders created.\")\n",
    "\n",
    "# Get dataset sizes and class names\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# --- Step 4: Model Loading and Modification (timm) ---\n",
    "print(\"Creating model...\")\n",
    "model_name = 'resnet18'\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "# Modify the final classification layer\n",
    "if hasattr(model, 'fc'):\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "elif hasattr(model, 'classifier'):\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "elif hasattr(model, 'head'):\n",
    "    if isinstance(model.head, nn.Sequential) and isinstance(model.head[-1], nn.Linear):\n",
    "        num_ftrs = model.head[-1].in_features\n",
    "        model.head[-1] = nn.Linear(num_ftrs, num_classes)\n",
    "    elif isinstance(model.head, nn.Linear):\n",
    "        num_ftrs = model.head.in_features\n",
    "        model.head = nn.Linear(num_ftrs, num_classes)\n",
    "else:\n",
    "    raise AttributeError(f\"Couldn't find a common classification head for model: {model_name}. Please inspect its structure or choose another model.\")\n",
    "print(\"Model created and modified.\")\n",
    "\n",
    "# Move the model to the chosen device (MPS or CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# --- Step 5: Training Loop ---\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            print(f\"Starting {phase} phase for Epoch {epoch}...\")\n",
    "            total_batches = len(dataloaders[phase])\n",
    "\n",
    "            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                # Print progress every 100 batches, or at the start/end of phase\n",
    "                if (i + 1) % 100 == 0 or (i + 1) == total_batches or (i + 1) == 1:\n",
    "                    print(f\"   {phase.capitalize()} Batch [{i+1}/{total_batches}]\")\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            print(f\"Finished {phase} phase for Epoch {epoch}.\")\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# This ensures the training function is called when the notebook is run directly\n",
    "if __name__ == '__main__':\n",
    "    model_trained = train_model(model, criterion, optimizer, scheduler, num_epochs=10)\n",
    "    # --- Step 6: Saving the Trained Model ---\n",
    "    # Save the state_dict (weights) of your best performing model.\n",
    "    model_save_path = 'app/image_classification_model.pth'\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True) # Ensure 'app' directory exists\n",
    "    torch.save(model_trained.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2c7063-ef52-402e-a9ed-9827687513d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Image Classifier (venv)",
   "language": "python",
   "name": "ml_image_classifier_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
